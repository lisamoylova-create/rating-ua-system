import pandas as pd
import logging
import psycopg2
import os
from decimal import Decimal

def get_db_connection():
    """Get direct PostgreSQL connection"""
    return psycopg2.connect(os.environ.get("DATABASE_URL"))

def clean_text_for_sql(value):
    """Clean text value for SQL insertion"""
    if pd.isna(value) or value is None or str(value).lower() == 'nan':
        return None
    
    text = str(value).strip()
    
    # Remove NULL bytes and other problematic characters
    text = text.replace('\x00', '').replace('\r\n', ' ').replace('\n', ' ').replace('\r', ' ')
    text = text.replace('\t', ' ').replace('\\', '/').replace("'", "''")  # Escape single quotes
    
    # Limit length
    if len(text) > 500:
        text = text[:500]
    
    return text if text and text.lower() != 'nan' else None

def process_second_file_ultra_fast(df):
    """–£–õ–¨–¢–†–ê-–®–í–ò–î–ö–ê –≤–µ—Ä—Å—ñ—è –∑ –æ–±—Ä–æ–±–∫–æ—é –ø–æ —á–∞—Å—Ç–∏–Ω–∞—Ö —ñ bulk –æ–ø–µ—Ä–∞—Ü—ñ—è–º–∏"""
    success_count = 0
    error_count = 0
    
    logging.info(f"üöÄ ULTRA-FAST: Processing actualization file with {len(df)} rows")
    
    # –ó–Ω–∞–π—Ç–∏ –Ñ–îR–ü–û–£ –∫–æ–ª–æ–Ω–∫—É (–≥–Ω—É—á–∫–∏–π –ø–æ—à—É–∫)
    edrpou_col = None
    for col_name in df.columns:
        if any(keyword in col_name.upper() for keyword in ['–Ñ–î–†–ü–û–£', 'EDRPOU']):
            edrpou_col = col_name
            logging.info(f"Found EDRPOU column: '{col_name}'")
            break
    
    if not edrpou_col:
        logging.error("EDRPOU column not found in actualization file")
        return 0, len(df)
    
    # –û—Ç—Ä–∏–º–∞—Ç–∏ –≤—Å—ñ –Ñ–îR–ü–û–£ —Ç–∞ ID –∑ –±–∞–∑–∏ –æ–¥–Ω–∏–º –∑–∞–ø–∏—Ç–æ–º
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        logging.info("üìä Loading all companies from database...")
        cursor.execute("SELECT edrpou, id FROM companies")
        db_companies = {row[0]: row[1] for row in cursor.fetchall()}
        logging.info(f"Loaded {len(db_companies)} companies from database")
        
        # –§—ñ–ª—å—Ç—Ä—É–≤–∞—Ç–∏ —Ñ–∞–π–ª –∞–∫—Ç—É–∞–ª—ñ–∑–∞—Ü—ñ—ó - –∑–∞–ª–∏—à–∏—Ç–∏ —Ç—ñ–ª—å–∫–∏ —ñ—Å–Ω—É—é—á—ñ –∫–æ–º–ø–∞–Ω—ñ—ó
        df[edrpou_col] = df[edrpou_col].astype(str)
        existing_mask = df[edrpou_col].isin(db_companies.keys())
        df_existing = df[existing_mask].copy()
        
        logging.info(f"üéØ Found {len(df_existing)} companies from actualization file that exist in database")
        logging.info(f"Skipping {len(df) - len(df_existing)} companies not found in database")
        
        if len(df_existing) == 0:
            logging.warning("No matching companies found - nothing to actualize")
            return 0, len(df)
        
        # –°–£–ü–ï–†-–®–í–ò–î–ö–ò–ô –ü–Ü–î–•–Ü–î: –û–±—Ä–æ–±–∏—Ç–∏ –í–°–Ü –¥–∞–Ω—ñ –æ–¥—Ä–∞–∑—É –±–µ–∑ —Ü–∏–∫–ª—ñ–≤
        logging.info(f"‚ö° SUPER-FAST: Processing all {len(df_existing)} companies at once")
        
        try:
            # –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ç–∏–º—á–∞—Å–æ–≤—É —Ç–∞–±–ª–∏—Ü—é –¥–ª—è bulk update
            cursor.execute("""
                CREATE TEMPORARY TABLE temp_updates (
                    company_id INTEGER,
                    first_name TEXT,
                    middle_name TEXT,
                    last_name TEXT,
                    work_phone TEXT,
                    corporate_site TEXT,
                    work_email TEXT,
                    company_status TEXT,
                    director TEXT,
                    government_purchases NUMERIC,
                    tender_count INTEGER,
                    initials TEXT
                )
            """)
            
            # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –í–°–Ü –¥–∞–Ω—ñ –¥–ª—è –æ–¥–Ω–æ–≥–æ bulk INSERT
            insert_data = []
            
            for index, row in df_existing.iterrows():
                try:
                    edrpou = str(row[edrpou_col])
                    company_id = db_companies[edrpou]
                    
                    # –û–±—Ä–æ–±–∏—Ç–∏ –≤—Å—ñ –ø–æ–ª—è
                    first_name = clean_text_for_sql(
                        row.get('–Ü–º\'—è') or row.get('–ò–º—è') or row.get('First Name') or 
                        row.get('first_name') or row.get('–Ü–º\'—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞')
                    )
                    
                    middle_name = clean_text_for_sql(
                        row.get('–ü–æ –±–∞—Ç—å–∫–æ–≤—ñ') or row.get('–û—Ç—á–µ—Å—Ç–≤–æ') or row.get('Middle Name') or
                        row.get('middle_name') or row.get('–ü–æ –±–∞—Ç—å–∫–æ–≤—ñ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞')
                    )
                    
                    last_name = clean_text_for_sql(
                        row.get('–ü—Ä—ñ–∑–≤–∏—â–µ') or row.get('–§–∞–º–∏–ª–∏—è') or row.get('Last Name') or
                        row.get('last_name') or row.get('–ü—Ä—ñ–∑–≤–∏—â–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞')
                    )
                    
                    work_phone = clean_text_for_sql(
                        row.get('–†–æ–±–æ—á–∏–π —Ç–µ–ª–µ—Ñ–æ–Ω') or row.get('–†–∞–±–æ—á–∏–π —Ç–µ–ª–µ—Ñ–æ–Ω') or 
                        row.get('Work Phone') or row.get('work_phone') or row.get('–¢–µ–ª. —Ä–æ–±')
                    )
                    
                    corporate_site = clean_text_for_sql(
                        row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏–π —Å–∞–π—Ç') or row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π —Å–∞–π—Ç') or
                        row.get('Corporate Site') or row.get('corporate_site') or row.get('–°–∞–π—Ç')
                    )
                    
                    work_email = clean_text_for_sql(
                        row.get('–†–æ–±–æ—á–∏–π e-mail') or row.get('–†–∞–±–æ—á–∏–π e-mail') or
                        row.get('Work Email') or row.get('work_email') or row.get('Email')
                    )
                    
                    company_status = clean_text_for_sql(
                        row.get('–°—Ç–∞–Ω –∫–æ–º–ø–∞–Ω—ñ—ó') or row.get('–°—Ç–∞—Ç—É—Å –∫–æ–º–ø–∞–Ω–∏–∏') or
                        row.get('Company Status') or row.get('company_status') or row.get('–°—Ç–∞—Ç—É—Å')
                    )
                    
                    director = clean_text_for_sql(
                        row.get('–î–∏—Ä–µ–∫—Ç–æ—Ä') or row.get('Director') or row.get('director') or
                        row.get('–ö–µ—Ä—ñ–≤–Ω–∏–∫') or row.get('–ü–Ü–ë –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞')
                    )
                    
                    # –î–µ—Ä–∂–∑–∞–∫—É–ø—ñ–≤–ª—ñ (–∫–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ –≤ —á–∏—Å–ª–æ: —Ç–∞–∫=1, –Ω—ñ=0)
                    government_purchases = None
                    government_purchases_raw = row.get('–£—á–∞—Å—Ç—å —É –¥–µ—Ä–∂–∑–∞–∫—É–ø—ñ–≤–ª—è—Ö (–Ω–∞ 01.04.2020)') or row.get('–£—á–∞—Å—Ç–∏–µ –≤ –≥–æ—Å–∑–∞–∫—É–ø–∫–∞—Ö') or row.get('Government Purchases') or row.get('government_purchases') or row.get('–î–µ—Ä–∂–∑–∞–∫—É–ø—ñ–≤–ª—ñ')
                    if government_purchases_raw and not pd.isna(government_purchases_raw):
                        gov_str = str(government_purchases_raw).strip().lower()
                        if gov_str in ['—Ç–∞–∫', '–¥–∞', 'yes', '1', 'true']:
                            government_purchases = 1
                        elif gov_str in ['–Ω—ñ', '–Ω–µ—Ç', 'no', '0', 'false']:
                            government_purchases = 0
                    
                    # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ–Ω–¥–µ—Ä—ñ–≤
                    tender_count = None
                    tender_count_raw = row.get('–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ–Ω–¥–µ—Ä—ñ–≤') or row.get('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤') or row.get('Tender Count')
                    if tender_count_raw and not pd.isna(tender_count_raw):
                        try:
                            tender_str = str(tender_count_raw).strip().lower()
                            if tender_str not in ['–Ω—ñ', '–Ω–µ—Ç', '–Ω–µ–º–∞—î', '–Ω–µ–º–∞', 'no', 'none', '']:
                                tender_count = int(float(tender_str))
                                if tender_count < 0:  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –≤—ñ–¥'—î–º–Ω—ñ
                                    tender_count = None
                        except (ValueError, TypeError):
                            tender_count = None
                    
                    # –Ü–Ω—ñ—Ü—ñ–∞–ª–∏
                    initials = clean_text_for_sql(
                        row.get('–ò–Ω–∏—Ü–∏–∞–ª—ã –≤ –ø–∞–¥–µ–∂–µ') or row.get('–Ü–Ω—ñ—Ü—ñ–∞–ª–∏ –≤ –≤—ñ–¥–º—ñ–Ω–∫—É') or
                        row.get('Initials') or row.get('initials') or row.get('–Ü–Ω—ñ—Ü—ñ–∞–ª–∏')
                    )
                    
                    # –î–æ–¥–∞—Ç–∏ –¥–∞–Ω—ñ –¥–ª—è insert
                    row_data = [
                        company_id,
                        first_name,
                        middle_name,
                        last_name,
                        work_phone,
                        corporate_site,
                        work_email,
                        company_status,
                        director,
                        government_purchases,
                        tender_count,
                        initials
                    ]
                    insert_data.append(row_data)
                    
                except Exception as e:
                    logging.error(f"Error processing row {index}: {str(e)}")
                    error_count += 1
                    continue
            
            # –û–î–ò–ù –í–ï–õ–ò–ö–ò–ô BULK INSERT –¥–ª—è –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö
            logging.info(f"üí´ Bulk inserting {len(insert_data)} companies into temp table...")
            cursor.executemany("""
                INSERT INTO temp_updates VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, insert_data)
            
            # –û–î–ò–ù UPDATE –∑ JOIN –¥–ª—è –≤—Å—ñ—Ö –∫–æ–º–ø–∞–Ω—ñ–π –æ–¥—Ä–∞–∑—É
            logging.info(f"üöÄ Performing single bulk UPDATE with JOIN...")
            cursor.execute("""
                UPDATE companies 
                SET 
                    first_name = COALESCE(t.first_name, companies.first_name),
                    middle_name = COALESCE(t.middle_name, companies.middle_name),
                    last_name = COALESCE(t.last_name, companies.last_name),
                    work_phone = COALESCE(t.work_phone, companies.work_phone),
                    corporate_site = COALESCE(t.corporate_site, companies.corporate_site),
                    work_email = COALESCE(t.work_email, companies.work_email),
                    company_status = COALESCE(t.company_status, companies.company_status),
                    director = COALESCE(t.director, companies.director),
                    government_purchases = COALESCE(t.government_purchases, companies.government_purchases),
                    tender_count = COALESCE(t.tender_count, companies.tender_count),
                    initials = COALESCE(t.initials, companies.initials)
                FROM temp_updates t
                WHERE companies.id = t.company_id
            """)
            
            affected_rows = cursor.rowcount
            success_count = affected_rows
            conn.commit()
            
            # –í–∏–¥–∞–ª–∏—Ç–∏ —Ç–∏–º—á–∞—Å–æ–≤—É —Ç–∞–±–ª–∏—Ü—é
            cursor.execute("DROP TABLE temp_updates")
            
            logging.info(f"‚ö° SUPER-FAST COMPLETE: Updated {affected_rows} companies in one operation!")
            
        except Exception as e:
            conn.rollback()
            logging.error(f"Error in super-fast bulk update: {str(e)}")
            error_count = len(df_existing)
        
        logging.info(f"üéâ Ultra-fast actualization complete: {success_count} companies updated, {error_count} errors")
        
    except Exception as e:
        conn.rollback()
        logging.error(f"Database error during actualization: {str(e)}")
        return 0, len(df)
    finally:
        cursor.close()
        conn.close()
    
    return success_count, error_count