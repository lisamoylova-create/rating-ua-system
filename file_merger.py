"""
–ú–æ–¥—É–ª—å –¥–ª—è –∑–ª–∏—Ç—Ç—è —Ñ–∞–π–ª—ñ–≤ Excel –∑–∞ –ø—Ä–∏–Ω—Ü–∏–ø–æ–º –í–ü–† (VLOOKUP)
–¥–ª—è —Å–∏—Å—Ç–µ–º–∏ –†–µ–π—Ç–∏–Ω–≥.UA
"""
import pandas as pd
import logging
from datetime import datetime
from typing import Tuple, Dict, List

class ExcelFileMerger:
    """–ö–ª–∞—Å –¥–ª—è –∑–ª–∏—Ç—Ç—è –¥–≤–æ—Ö Excel —Ñ–∞–π–ª—ñ–≤ –∑–∞ –∫–æ–¥–æ–º –Ñ–î–†–ü–û–£"""
    
    def __init__(self):
        self.main_file_data = None
        self.additional_file_data = None
        self.merged_data = None
        self.merge_stats = {
            'total_main': 0,
            'total_additional': 0,
            'matched': 0,
            'not_actualized': 0,
            'final_count': 0
        }
    
    def load_main_file(self, file_path: str) -> bool:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –æ—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª (11 –∫–æ–ª–æ–Ω–æ–∫)"""
        try:
            df = pd.read_excel(file_path)
            df = self._normalize_columns(df)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –Ñ–î–†–ü–û–£
            if 'edrpou' not in df.columns:
                logging.error("–û—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É –Ñ–î–†–ü–û–£")
                return False
            
            self.main_file_data = df
            self.merge_stats['total_main'] = len(df)
            
            logging.info(f"‚úÖ –û—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {len(df)} –∑–∞–ø–∏—Å—ñ–≤")
            logging.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            
            return True
            
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É: {e}")
            return False
    
    def load_additional_file(self, file_path: str) -> bool:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π —Ñ–∞–π–ª (17 –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫)"""
        try:
            df = pd.read_excel(file_path)
            df = self._normalize_columns(df)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –Ñ–î–†–ü–û–£
            if 'edrpou' not in df.columns:
                logging.error("–î–æ–¥–∞—Ç–∫–æ–≤–∏–π —Ñ–∞–π–ª –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É –Ñ–î–†–ü–û–£")
                return False
            
            self.additional_file_data = df
            self.merge_stats['total_additional'] = len(df)
            
            logging.info(f"‚úÖ –î–æ–¥–∞—Ç–∫–æ–≤–∏–π —Ñ–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {len(df)} –∑–∞–ø–∏—Å—ñ–≤")
            logging.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            
            return True
            
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É: {e}")
            return False
    
    def _normalize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤ –∫–æ–ª–æ–Ω–æ–∫"""
        column_mapping = {
            '–∫–æ–¥ —î–¥—Ä–ø–æ—É': 'edrpou',
            '—î–¥—Ä–ø–æ—É': 'edrpou',
            'edrpou': 'edrpou',
            '–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏': 'name',
            '–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ 2': 'name',
            '–Ω–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó': 'name',
            '–∫–æ–º–ø–∞–Ω—ñ—è': 'name',
            'name': 'name',
            '–∫–≤–µ–¥': 'kved_code',
            'kved': 'kved_code',
            '–æ—Å–Ω–æ–≤–Ω–∏–π –≤–∏–¥ –¥—ñ—è–ª—å–Ω–æ—Å—Ç—ñ (–∫–≤–µ–¥)': 'kved_description',
            '–æ—Å–Ω–æ–≤–Ω–∏–π –≤–∏–¥ –¥—ñ—è–ª—å–Ω–æ—Å—Ç—ñ (–∫–≤–µ–¥) 2': 'kved_description',
            '–æ—Å–Ω–æ–≤–Ω–∏–π –≤–∏–¥ –¥—ñ—è–ª—å–Ω–æ—Å—Ç—ñ': 'kved_description',
            '–¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å': 'kved_description',
            '–ø–µ—Ä—Å–æ–Ω–∞–ª (2019 —Ä.)': 'personnel_2019',
            '–ø–µ—Ä—Å–æ–Ω–∞–ª (2019 —Ä.) 2': 'personnel_2019',
            '–ø–µ—Ä—Å–æ–Ω–∞–ª': 'personnel_2019',
            'personnel': 'personnel_2019',
            '–æ–±–ª–∞—Å—Ç—å': 'region',
            '–æ–±–ª–∞—Å—Ç—å 2': 'region',
            '—Ä–µ–≥—ñ–æ–Ω': 'region',
            'region': 'region',
            '—Ç–µ–ª–µ—Ñ–æ–Ω': 'phone',
            'phone': 'phone',
            '–∞–¥—Ä–µ—Å–∞ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó': 'address',
            '–∞–¥—Ä–µ—Å–∞ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó 2': 'address',
            '–∞–¥—Ä–µ—Å–∞': 'address',
            'address': 'address',
            '—á–∏—Å—Ç–∏–π –¥–æ—Ö—ñ–¥ –≤—ñ–¥ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø—Ä–æ–¥—É–∫—Ü—ñ—ó': 'revenue',
            '—á–∏—Å—Ç–∏–π –¥–æ—Ö—ñ–¥ –≤—ñ–¥ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø—Ä–æ–¥—É–∫—Ü—ñ—ó (—Ç–æ–≤–∞—Ä—ñ–≤, —Ä–æ–±—ñ—Ç, –ø–æ—Å–ª—É–≥)': 'revenue',
            '—á–∏—Å—Ç–∏–π –¥–æ—Ö—ñ–¥ (–≤–∏—Ä—É—á–∫–∞) –≤—ñ–¥ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø—Ä–æ–¥—É–∫—Ü—ñ—ó': 'revenue',
            '–¥–æ—Ö—ñ–¥ –≤—ñ–¥ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó': 'revenue',
            '–¥–æ—Ö—ñ–¥': 'revenue',
            '–≤–∏—Ä—É—á–∫–∞': 'revenue',
            '–≤–∏—Ä—É—á–∫–∞, —Ç–∏—Å. –≥—Ä–Ω (2019 —Ä.)': 'revenue',
            '–æ–±–æ—Ä–æ—Ç': 'revenue',
            'revenue': 'revenue',
            '—á–∏—Å—Ç–∏–π —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –ø—Ä–∏–±—É—Ç–æ–∫': 'profit',
            '—á–∏—Å—Ç–∏–π —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–ø—Ä–∏–±—É—Ç–æ–∫)': 'profit',
            '—Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ –æ–ø–æ–¥–∞—Ç–∫—É–≤–∞–Ω–Ω—è': 'profit',
            '–ø—Ä–∏–±—É—Ç–æ–∫ (–∑–±–∏—Ç–æ–∫) –¥–æ –æ–ø–æ–¥–∞—Ç–∫—É–≤–∞–Ω–Ω—è': 'profit',
            '—á–∏—Å—Ç–∏–π –ø—Ä–∏–±—É—Ç–æ–∫ (–∑–±–∏—Ç–æ–∫)': 'profit',
            '–ø—Ä–∏–±—É—Ç–æ–∫': 'profit',
            '—á–∏—Å—Ç–∏–π –ø—Ä–∏–±—É—Ç–æ–∫': 'profit',
            'profit': 'profit',
            '—Ä–∞–∑–º–µ—Ä': 'size',
            '—Ä–æ–∑–º—ñ—Ä': 'size',
            'size': 'size',
            
            # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑ –¥—Ä—É–≥–æ–≥–æ —Ñ–∞–π–ª—É
            '—Ä–∞–±–æ—á–∏–π —Ç–µ–ª–µ—Ñ–æ–Ω': 'work_phone',
            '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π —Å–∞–π—Ç': 'corporate_site',
            '—Ä–∞–±–æ—á–∏–π e-mail': 'work_email',
            '—Å—Ç–∞–Ω –∫–æ–º–ø–∞–Ω—ñ—ó': 'company_status',
            '–¥–∏—Ä–µ–∫—Ç–æ—Ä': 'director',
            '—É—á–∞—Å—Ç—å —É –¥–µ—Ä–∂–∑–∞–∫—É–ø—ñ–≤–ª—è—Ö (–Ω–∞ 01.04.2020)': 'government_purchases',
            '–∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ–Ω–¥–µ—Ä—ñ–≤': 'tender_count',
            '–∏–Ω–∏—Ü–∏–∞–ª—ã –≤ –ø–∞–¥–µ–∂–µ': 'initials',
            '–∏–º—è': 'first_name',
            '–æ—Ç—á–µ—Å—Ç–≤–æ': 'middle_name',
            '—Ñ–∞–º–∏–ª–∏—è': 'last_name'
        }
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤ –∫–æ–ª–æ–Ω–æ–∫
        df.columns = df.columns.astype(str).str.lower().str.strip()
        df.columns = [' '.join(col.split()) for col in df.columns]
        df = df.rename(columns=column_mapping)
        
        return df
    
    def merge_files(self, ranking_name: str = None) -> pd.DataFrame:
        """–û–±'—î–¥–Ω—É—î —Ñ–∞–π–ª–∏ –∑–∞ –ø—Ä–∏–Ω—Ü–∏–ø–æ–º –í–ü–† (VLOOKUP)"""
        if self.main_file_data is None or self.additional_file_data is None:
            logging.error("–°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –æ–±–∏–¥–≤–∞ —Ñ–∞–π–ª–∏")
            return None
        
        try:
            # –û–±'—î–¥–Ω–∞–Ω–Ω—è –ø–æ –Ñ–î–†–ü–û–£ (LEFT JOIN - –∑–∞–ª–∏—à–∞—î–º–æ –≤—Å—ñ –∑–∞–ø–∏—Å–∏ –∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É)
            merged = self.main_file_data.merge(
                self.additional_file_data, 
                on='edrpou', 
                how='left', 
                suffixes=('', '_additional')
            )
            
            # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±—É–¥—å-—è–∫–æ—ó –∫–æ–ª–æ–Ω–∫–∏ –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É)
            additional_columns = [col for col in merged.columns if col.endswith('_additional')]
            if additional_columns:
                matched_count = merged[additional_columns[0]].notna().sum()
                not_actualized_count = merged[additional_columns[0]].isna().sum()
            else:
                matched_count = 0
                not_actualized_count = len(merged)
            
            self.merge_stats['matched'] = matched_count
            self.merge_stats['not_actualized'] = not_actualized_count
            self.merge_stats['final_count'] = len(merged)
            
            # –î–æ–¥–∞–≤–∞–Ω–Ω—è —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
            current_year = datetime.now().year
            
            merged['–ò—Å—Ç–æ—á–Ω–∏–∫'] = f"–£–∫—Ä–∞—ó–Ω–∞ {current_year}"
            merged['–¢–û–ü'] = 0  # –ë—É–¥–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø—ñ—Å–ª—è —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è
            merged['–ó–∞–≥–∞–ª—å–Ω–∞ –∫-—Ç—å'] = len(merged)  # –ë—É–¥–µ –æ–Ω–æ–≤–ª–µ–Ω–æ –ø—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–∫—Ç—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
            additional_columns = [col for col in merged.columns if col.endswith('_additional')]
            if additional_columns:
                merged['–ê–∫—Ç—É–∞–ª—ñ–∑–æ–≤–∞–Ω–æ'] = merged[additional_columns[0]].notna().map({True: '—Ç–∞–∫', False: '–Ω—ñ'})
                
                # –û–±'—î–¥–Ω—É—î–º–æ –Ω–∞–∑–≤–∏, —è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ name_additional
                if 'name_additional' in merged.columns:
                    merged['name'] = merged['name_additional'].fillna(merged['name'])
            else:
                merged['–ê–∫—Ç—É–∞–ª—ñ–∑–æ–≤–∞–Ω–æ'] = '–Ω—ñ'
            
            # –í–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—é–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫
            columns_to_drop = [col for col in merged.columns if col.endswith('_additional')]
            merged = merged.drop(columns=columns_to_drop)
            
            self.merged_data = merged
            
            logging.info(f"‚úÖ –§–∞–π–ª–∏ –æ–±'—î–¥–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
            logging.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–ª–∏—Ç—Ç—è:")
            logging.info(f"   ‚Ä¢ –û—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª: {self.merge_stats['total_main']} –∑–∞–ø–∏—Å—ñ–≤")
            logging.info(f"   ‚Ä¢ –î–æ–¥–∞—Ç–∫–æ–≤–∏–π —Ñ–∞–π–ª: {self.merge_stats['total_additional']} –∑–∞–ø–∏—Å—ñ–≤")
            logging.info(f"   ‚Ä¢ –ó–Ω–∞–π–¥–µ–Ω–æ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω—å: {matched_count}")
            logging.info(f"   ‚Ä¢ –ù–µ –∞–∫—Ç—É–∞–ª—ñ–∑–æ–≤–∞–Ω–æ: {not_actualized_count}")
            logging.info(f"   ‚Ä¢ –§—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(merged)} –∑–∞–ø–∏—Å—ñ–≤")
            
            return merged
            
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±'—î–¥–Ω–∞–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤: {e}")
            return None
    
    def get_merged_data(self) -> pd.DataFrame:
        """–ü–æ–≤–µ—Ä—Ç–∞—î –æ–±'—î–¥–Ω–∞–Ω—ñ –¥–∞–Ω—ñ"""
        return self.merged_data
    
    def get_merge_statistics(self) -> Dict:
        """–ü–æ–≤–µ—Ä—Ç–∞—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±'—î–¥–Ω–∞–Ω–Ω—è"""
        return self.merge_stats
    
    def update_ranking_columns(self, total_companies_in_ranking: int, total_companies_in_category: int):
        """–û–Ω–æ–≤–ª—é—î —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –ø—ñ—Å–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ä–µ–π—Ç–∏–Ω–≥—É"""
        if self.merged_data is not None:
            # –û–Ω–æ–≤–ª—é—î–º–æ –¢–û–ü (–∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–ø–∞–Ω—ñ–π —É —Ä–µ–π—Ç–∏–Ω–≥—É)
            self.merged_data.loc[self.merged_data.index < total_companies_in_ranking, '–¢–û–ü'] = total_companies_in_ranking
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å —É –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
            self.merged_data['–ó–∞–≥–∞–ª—å–Ω–∞ –∫-—Ç—å'] = total_companies_in_category
    
    def preview_merged_data(self, rows: int = 10) -> pd.DataFrame:
        """–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥ –æ–±'—î–¥–Ω–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""
        if self.merged_data is None:
            return pd.DataFrame()
        
        # –ü–æ–∫–∞–∑—É—î–º–æ –≤–∞–∂–ª–∏–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        preview_columns = [
            'edrpou', 'name', 'kved_code', 'region', 'personnel_2019', 
            'revenue', 'profit', '–ò—Å—Ç–æ—á–Ω–∏–∫', '–¢–û–ü', '–ó–∞–≥–∞–ª—å–Ω–∞ –∫-—Ç—å', '–ê–∫—Ç—É–∞–ª—ñ–∑–æ–≤–∞–Ω–æ'
        ]
        
        available_columns = [col for col in preview_columns if col in self.merged_data.columns]
        
        return self.merged_data[available_columns].head(rows)
    
    def export_to_csv(self, file_path: str) -> bool:
        """–ï–∫—Å–ø–æ—Ä—Ç –æ–±'—î–¥–Ω–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É CSV –∑ —É—Å—ñ–º–∞ 33 –∫–æ–ª–æ–Ω–∫–∞–º–∏"""
        if self.merged_data is None:
            logging.error("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É")
            return False
        
        try:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —â–æ —É –Ω–∞—Å —î –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏
            logging.info(f"üìä –ï–∫—Å–ø–æ—Ä—Ç CSV –∑ {len(self.merged_data.columns)} –∫–æ–ª–æ–Ω–∫–∞–º–∏")
            logging.info(f"üìä –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤: {len(self.merged_data)}")
            
            self.merged_data.to_csv(file_path, index=False, encoding='utf-8')
            
            logging.info(f"‚úÖ –î–∞–Ω—ñ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —É {file_path}")
            return True
            
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –µ–∫—Å–ø–æ—Ä—Ç—É CSV: {e}")
            return False